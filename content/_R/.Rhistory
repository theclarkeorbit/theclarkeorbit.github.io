setwd("~//Dropbox/website/")
# if Mac
# system("bash publish_on_mac.sh")
# if ubuntu
#system("git clone --recursive https://github.com/getpelican/pelican-themes ~/pelican-themes")
# system("pip install markdown typogrify beautifulsoup4 pelican")
system("bash publishsite.sh")
library(torch)
library(luz)
library(tidyverse) #Because what can one do without the tidyverse
library(ggthemes) #for Tufte
sentence <- "Life is short, eat dessert first"
# Remove the comma and split the sentence into words
words <- strsplit(gsub(",", "", sentence), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first, okay."
# Remove the comma and split the sentence into words
words <- strsplit(gsub(",", "", sentence), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first, okay."
# Replace all non-word characters with spaces and split the sentence into words
words <- strsplit(gsub("[^\\w\\s]", " ", sentence), "\\s+")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first"
# Remove the comma and split the sentence into words
words <- strsplit(gsub(",", "", sentence), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first"
# Remove the comma and split the sentence into words
words <- strsplit(gsub("[^\\w\\s]", "", sentence), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first"
# Remove the comma and split the sentence into words
words <- strsplit(gsub("[^\w\s]", "", sentence), " ")[[1]]
sentence <- "Life is short, eat dessert first"
# Remove the comma and split the sentence into words
words <- strsplit(gsub("[^ws]", "", sentence), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " +"), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", "+"), " ")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first is short", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first eat short dessert", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
sentence <- "Life is short, eat dessert first - okay? okay."
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices - the dictionary
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first eat short dessert", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices - the dictionary
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first eat short dessert", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices - the dictionary
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first eat short dessert", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
# Apply embedding to the sentence tensor
embedded_sentence <- embed(sentence_tensor)$detach()
?embed
?torch::nnf_embedding
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices - the dictionary
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first eat short dessert", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
# Define an embedding layer
embed <- nn_embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim)
sentence <- "Life is short, eat dessert first - okay?"
# Remove the comma and split the sentence into words
words <- strsplit(str_replace_all(sentence, "[[:punct:]]", " "), " +")[[1]]
# Sort the words
sorted_words <- sort(words)
# Create a named vector with indices - the dictionary
dc <- setNames(seq_along(sorted_words), sorted_words)
# Print the result
print(dc)
# Convert sentence words to indices using the dictionary
sentence_int <- sapply(strsplit(str_replace_all("first eat short dessert", "[[:punct:]]", " "), " +")[[1]], function(x) dc[x])
# Create a torch tensor from the indices
sentence_tensor <- torch_tensor(sentence_int, dtype = torch_long())
# Print the tensor
print(sentence_tensor)
vocab_size <- 50000
embedding_dim <- 3
# Define an embedding layer
embed <- nn_embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim)
# Apply embedding to the sentence tensor
embedded_sentence <- embed(sentence_tensor)$detach()
# Print the embedded sentence and its shape
print(embedded_sentence)
print(dim(embedded_sentence))
?nn_multihead_attention
attention_l <- nn_multihead_attention(embed_dim = 10, num_heads = 1)
attention_l(embedded_sentence)
attention_l(embedded_sentence)
attention_l(embedded_sentence)$detach()
attention_1
attention_l <- nn_multihead_attention(embed_dim = 3, num_heads = 1)
attention_1
attention_l
attention_l(embedded_sentence)
attention_l
?nnf_multi_head_attention_forward
attention_l(embedded_sentence, embedded_sentence, embedded_sentence)
?nn_multihead_attention
query <- embedded_sentence |> unsqueeze()
query <- embedded_sentence$unsqueeze()
query <- embedded_sentence$unsqueeze(1)
query <- embedded_sentence$unsqueeze(1)$unsqueeze(1)
dim(query)
query <- embedded_sentence$unsqueeze(3)
dim(query)
query <- embedded_sentence$unsqueeze(1)
attention_l(query,query,query)
query <- embedded_sentence$unsqueeze(2)
attention_l(query,query,query)
embedded_sentence |> dim()
query |> dim()
dir <- "~/.torch-datasets"
img_ds <- tiny_imagenet_dataset(
dir,
download = TRUE,
transform = function(x) {
x %>%
transform_to_tensor()
}
)
dir <- "~/.torch-datasets"
library(torchvision)
img_ds <- tiny_imagenet_dataset(
dir,
download = TRUE,
transform = function(x) {
x %>%
transform_to_tensor()
}
)
getOption('timeout')
options(timeout=100)
options(timeout=100000)
library(torch)
library(luz)
library(torchvision)
library(tidyverse) #Because what can one do without the tidyverse
library(ggthemes) #for Tufte
dir <- "~/.torch-datasets"
img_ds <- tiny_imagenet_dataset(
dir,
download = TRUE,
transform = function(x) {
x %>%
transform_to_tensor()
}
)
