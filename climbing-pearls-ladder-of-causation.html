<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>"Climbing Pearl's Ladder of Causation" - p. bhogale</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href=".//images/gravtar.jpg" rel="icon">

<link rel="canonical" href="./climbing-pearls-ladder-of-causation.html">

        <meta name="author" content="pras" />
        <meta name="description" content="Disclaimer: statistics is hard - the chief skill seems to be the ability to avoid deluding oneself and others. This is something that is best and quickest learned via an apprenticeship in a group of careful thinkers who care about getting things right. Tutorials like these can be misleading, in that …" />

        <meta property="og:site_name" content="p. bhogale" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="&#34;Climbing Pearl&#39;s Ladder of Causation&#34;"/>
        <meta property="og:url" content="./climbing-pearls-ladder-of-causation.html"/>
        <meta property="og:description" content="Disclaimer: statistics is hard - the chief skill seems to be the ability to avoid deluding oneself and others. This is something that is best and quickest learned via an apprenticeship in a group of careful thinkers who care about getting things right. Tutorials like these can be misleading, in that …"/>
        <meta property="article:published_time" content="2025-10-01" />
            <meta property="article:section" content="data_sci_tech" />
            <meta property="article:author" content="pras" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="./theme/css/bootstrap.min.css" type="text/css"/>
    <link href="./theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="./theme/css/pygments/monokai.css" rel="stylesheet">
    <link rel="stylesheet" href="./theme/css/style.css" type="text/css"/>

        <link href="./feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="p. bhogale ATOM Feed"/>

        <link href="./feeds/data_sci_tech.atom.xml" type="application/atom+xml" rel="alternate"
              title="p. bhogale data_sci_tech ATOM Feed"/>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-115756026-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', UA-115756026-1);
    </script>
    <!-- End Google Analytics Code -->
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="./" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src=".//images/gravtar.jpg" width=""/> p. bhogale            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="./pages/about.html">
                             About
                          </a></li>
                        <li >
                            <a href="./category/blog.html">Blog</a>
                        </li>
                        <li class="active">
                            <a href="./category/data_sci_tech.html">Data_sci_tech</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<style>
	#banner{
	    background-image:url(".//images/banner.jpg");
	}
</style>

<div id="banner">
	<div class="container">
		<div class="copy">
			<h1>p. bhogale</h1>
				<p class="intro">Data Sci, Quant Fin, Quant Bio.</p>
		</div>
	</div>
</div><!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="./climbing-pearls-ladder-of-causation.html"
                       rel="bookmark"
                       title="Permalink to "Climbing Pearl's Ladder of Causation"">
                        "Climbing Pearl's Ladder of Causation"
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2025-10-01T00:00:00+02:00"> Wed 01 October 2025</time>
    </span>





    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p><strong>Disclaimer</strong>: statistics is hard - the chief skill seems to be the ability to avoid deluding oneself and others. This is something that is best and quickest learned via an apprenticeship in a group of careful thinkers who care about getting things right. Tutorials like these can be misleading, in that they give the illusion of competence. This tutorial was written as a way for me to learn, not as an exposition by an experienced practitioner.  However, I hope this serves as a useful read, expecially since I link to other, deeper resources.</p>
<p>If you want to peek into how a statistician thinking carefully approaches this subject, you could hardly do better than the <a href="https://mixtape.scunning.com/">Causal Mixtape</a> and <a href="https://xcelab.net/rm/">Statistical Rethinking</a>. If you are totally new to all this causal stuff, do read <a href="https://dl.acm.org/doi/10.5555/3238230">The Book of Why</a> (no, really). </p>
<p>This article heavily uses the <code>quartets</code> package and the <a href="https://www.tandfonline.com/doi/full/10.1080/26939169.2023.2276446">paper that introduces it</a> but there is also another <a href="https://sites.stat.columbia.edu/gelman/research/published/causal_quartet_second_revision.pdf">paper</a>(pdf) and associated <a href="https://github.com/jhullman/causalQuartet">package</a> on a very similar theme. For analysing DAGs, we rely heavily on the wonderful <code>dagitty</code> package, and we visualize using <code>ggdag</code>. </p>
<h3>The wind/rudder problem</h3>
<p>Consider a dynamic system consisting of three variables: wind speed <span class="math">\(W\)</span>, rudder angle <span class="math">\(R\)</span>, and boat heading <span class="math">\(D\)</span> (direction). An observer on shore measures <span class="math">\(R\)</span> and <span class="math">\(D\)</span> continuously over time, with the goal of understanding whether rudder adjustments causally affect the boat's trajectory. The wind <span class="math">\(W\)</span>, however, remains unobserved.</p>
<p>The data-generating process works as follows. The wind <span class="math">\(W\)</span> exerts a direct causal influence on the boat's heading: <span class="math">\(W \rightarrow D\)</span>. A skilled sailor observes the wind and adjusts the rudder to compensate, creating a second causal relationship: <span class="math">\(W \rightarrow R\)</span>. The rudder also directly affects heading through hydrodynamic forces: <span class="math">\(R \rightarrow D\)</span>. Crucially, the sailor's adjustment strategy is systematic: rudder angle is set to approximately counteract the wind's effect, meaning <span class="math">\(R \approx -\alpha W\)</span> for some coefficient <span class="math">\(\alpha &gt; 0\)</span>.</p>
<p>After collecting observational data, the observer computes <span class="math">\(\text{cor}(R, D)\)</span> and finds it to be approximately zero. The naive conclusion follows: rudder angle has no relationship with boat direction, therefore the rudder is ineffective.</p>
<p>The error stems from <strong>endogeneity</strong>. In econometrics and causal inference, a variable is called endogenous when it is correlated with the error term or, equivalently, when it is determined by other variables in the system that also affect the outcome. Here, the rudder angle <span class="math">\(R\)</span> is endogenous because it is not set independently of the other factors affecting direction, <span class="math">\(R\)</span> is systematically determined by <span class="math">\(W\)</span> (via the sailor working to keep the boat's heading constant), which is itself a common cause of both <span class="math">\(R\)</span> and <span class="math">\(D\)</span>. </p>
<p>This creates what Pearl calls <strong>confounding</strong>: the naive correlation <span class="math">\(\text{cor}(R, D)\)</span> confounds the true causal effect of <span class="math">\(R\)</span> on <span class="math">\(D\)</span> with the spurious correlation induced by their common cause <span class="math">\(W\)</span>. This and other seemingly intractable issues like <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2343788">Simpson's paradox</a> (association between two variables changes sign when conditioned on a third) are all unravelled once we encode our knowledge of the world into causal relationships between variables and test how valid these are in light of data. </p>
<p>At the end of this article, you should be able to do a basic causal analysis on an appropriate dataset with dagitty and have an intuition about what it is you are saying when you estimate direct and indirect causal effects.</p>
<h3>The data.</h3>
<p>Let's load the causal quartet and take a first look. These four datasets were carefully constructed to have identical correlations between x and y, but as we'll discover, they tell four completely different causal stories.</p>
<div class="highlight"><pre><span></span><code><span class="c1">## # A tibble: 10 × 6</span>
<span class="c1">##    dataset        exposure outcome covariate    u1     u2</span>
<span class="c1">##    &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">##  1 (1) Collider      0.625 -0.0261    -0.659 NA    NA    </span>
<span class="c1">##  2 (2) Confounder    1.67   3.09       2.07  NA    NA    </span>
<span class="c1">##  3 (4) M-Bias       -2.53  -2.56     -12.5   -1.54 -0.355</span>
<span class="c1">##  4 (1) Collider      0.743  0.766      1.03  NA    NA    </span>
<span class="c1">##  5 (1) Collider     -0.653  0.0510     1.31  NA    NA    </span>
<span class="c1">##  6 (1) Collider     -0.401  0.617      0.207 NA    NA    </span>
<span class="c1">##  7 (3) Mediator     -0.590 -0.482     -0.170 NA    NA    </span>
<span class="c1">##  8 (1) Collider     -0.451  0.267     -0.156 NA    NA    </span>
<span class="c1">##  9 (1) Collider      1.97   1.54       1.85  NA    NA    </span>
<span class="c1">## 10 (2) Confounder   -0.421  0.887     -0.562 NA    NA</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span> # A tibble: 4 × 7
<span class="gu">##</span>   dataset            n  mean_x  mean_y  sd_x  sd_y cor_xy
<span class="gu">##</span>   &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
<span class="gu">##</span> 1 (1) Collider     100 -0.146  -0.0136  1.05  1.37  0.769
<span class="gu">##</span> 2 (2) Confounder   100 -0.0291 -0.0357  1.30  1.77  0.735
<span class="gu">##</span> 3 (3) Mediator     100 -0.0317 -0.0392  1.03  1.72  0.594
<span class="gu">##</span> 4 (4) M-Bias       100  0.136  -0.0809  1.48  2.06  0.724
</code></pre></div>

<p><img alt="center" src="/figures/causality1/load-data-1.png"></p>
<p>All four datasets have nearly identical means, standard deviations, and correlations. If we only looked at these summary statistics, we might think they're the same data. They look similar, but the underlying causal mechanisms are completely different. To see why, we need to understand Pearl's ladder.</p>
<h3>The ladder</h3>
<p>Judea Pearl posits that causal reasoning exists on three distinct levels. Each rung requires more sstructure than the one below it, and each rung enables us to answer questions that are impossible at lower levels.</p>
<p><strong>Rung 1: association</strong> - The world of pure observation. We ask "what is?" We observe patterns and correlations. This is the domain of traditional statistics. We can compute things like P(Y|X), the probability of Y given that we observe X. Remarkably, even at this rung of the ladder, causal assumptions made explicit can - sometimes - be falsified because different causal relationships result in different implications for conditional distributions between variables.</p>
<p><strong>Rung 2: intervention</strong> - The world of action and experiments. We ask "what if I do?" We imagine actively manipulating one variable and seeing what happens to another. This is the domain of randomized controlled trials and policy evaluation. We compute things like P(Y|do(X)), the probability of Y if we <em>force</em> X to take a particular value - in other words, severe X from this causes and set it to a value we choose. In practice, this is often hard to do so the ability to reason about interventions without making them (by modifying the DAG and working out the implications) is very useful.</p>
<p><strong>Rung 3: counterfactuals</strong> - The world of imagination and retrospection. We ask "what would have been?" We look at what actually happened and imagine how it would have been different under alternative circumstances. This is the domain of individual-level causal attribution, regret, and responsibility. We compute things like "what would Y have been for this specific individual if X had been different?". Apart from the data and the DAG, we also need to add structural equations (functional relationships) that define how each arrow of the DAG is actualized. Then, we infer something about these functions based on the real data  - treatment A failed for Patient 2 tells us something - and thus we can attempt to answer a question like "Would Patient 2 have recovered with treatment B?". </p>
<p>Each rung requires adding something to what we had before. Let's climb the ladder step by step, using the causal quartet as our guide.</p>
<h3>Rung 1: association</h3>
<p>At the first rung, we're observing the world and looking for patterns. We have data, and we can compute conditional probabilities, correlations, and statistical associations. But we cannot distinguish between causation and correlation. All we can say is "when I see X, I tend to see Y."</p>
<h4>What we add: DAG structure</h4>
<p>To work at this level, we add a directed acyclic graph (DAG) that represents possible conditional independence relationships. The DAG is just a hypothesis about the structure of dependencies between variables. At this level, the edges don't necessarily mean "causes" - they just mean "statistically dependent."</p>
<p>The four datasets in the causal quartet actually correspond to four simple DAG structures. Let's take a look.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Dataset 1: Collider (X causes Y, Both cause Z)</span>
<span class="n">dag1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dagitty</span><span class="p">(</span><span class="s">&#39;dag {</span>
<span class="s">  exposure -&gt; outcome</span>
<span class="s">  exposure -&gt; covariate</span>
<span class="s">  outcome -&gt; covariate</span>
<span class="s">}&#39;</span><span class="p">)</span>

<span class="c1"># Dataset 2: Common cause / Confounder (Z causes both X and Y)</span>
<span class="n">dag2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dagitty</span><span class="p">(</span><span class="s">&#39;dag {</span>
<span class="s">  covariate -&gt; exposure</span>
<span class="s">  covariate -&gt; outcome</span>
<span class="s">  exposure -&gt; outcome</span>
<span class="s">}&#39;</span><span class="p">)</span>

<span class="c1"># Dataset 3: Mediation / Chain (X causes Z, Z causes Y)</span>
<span class="n">dag3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dagitty</span><span class="p">(</span><span class="s">&#39;dag {</span>
<span class="s">  exposure -&gt; covariate -&gt; outcome</span>
<span class="s">}&#39;</span><span class="p">)</span>

<span class="c1"># Dataset 4: M-bias (X and Y both cause Z)</span>
<span class="n">dag4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dagitty</span><span class="p">(</span><span class="s">&#39;dag {</span>
<span class="s">  u1 -&gt; covariate</span>
<span class="s">  u1 -&gt; exposure -&gt; outcome</span>
<span class="s">  u2 -&gt; covariate</span>
<span class="s">  u2 -&gt; outcome</span>
<span class="s">}&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">p1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">p2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">p3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">p4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">  </span><span class="nf">plot_layout</span><span class="p">(</span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</code></pre></div>

<p><img alt="center" src="/figures/causality1/unnamed-chunk-2-1.png"></p>
<p>While the headline stats are the same, the 4 data sets represent very different causal structures, seen above. </p>
<h4>Testing DAGs against data</h4>
<p>In a typical situation, the DAG is an explicit set of assumptions about the world generated by the scientist, and these need to be tested against the data. The key insight of the first rung of causation is that different DAG structures imply different patterns of conditional independence. Even though x and y are correlated in all four datasets, they have different relationships when we condition on the third variable z.</p>
<p>We can use the <strong>d-separation criterion</strong> (two variables are independent given your controls if no path between them can transmit information) to derive testable implications. The <code>dagitty</code> package does this automatically for us with the <code>impliedConditionalIndependencies</code> function.</p>
<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="nx">DAG</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">(</span><span class="nx">Collider</span><span class="p">)</span><span class="w"> </span><span class="nx">implies</span><span class="p">:</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="nx">DAG</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="p">(</span><span class="nx">Confounder</span><span class="p">)</span><span class="w"> </span><span class="nx">implies</span><span class="p">:</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="nx">DAG</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="p">(</span><span class="nx">Mediation</span><span class="p">)</span><span class="w"> </span><span class="nx">implies</span><span class="p">:</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span> exps _||_ otcm | cvrt
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="nx">DAG</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="p">(</span><span class="nx">M</span><span class="o">-</span><span class="nx">bias</span><span class="p">)</span><span class="w"> </span><span class="nx">implies</span><span class="p">:</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span> cvrt _||_ exps | u1
<span class="gu">##</span> cvrt _||_ otcm | exps, u2
<span class="gu">##</span> cvrt _||_ otcm | u1, u2
<span class="gu">##</span> exps _||_ u2
<span class="gu">##</span> otcm _||_ u1 | exps
<span class="gu">##</span> u1 _||_ u2
</code></pre></div>

<p>We see that DAGs 1,2 can't be falsified at Rung 1, since there are no conditional implications we can test (and which could potentially be false).</p>
<p>Before we start testing our DAG hypotheses with data, we need to understand what we're actually testing and how to interpret the results. This is subtle because the logic is <strong>inverted from typical hypothesis testing</strong>. The testing procedure works as follows:</p>
<ol>
<li>Extract all conditional independence implications from the DAG using d-separation</li>
<li>For each implication of the form <span class="math">\(X \perp Y \mid Z\)</span> (for example):</li>
<li>Regress <span class="math">\(X\)</span> on <span class="math">\(Z\)</span> to get residuals <span class="math">\(r_X\)</span></li>
<li>Regress <span class="math">\(Y\)</span> on <span class="math">\(Z\)</span> to get residuals <span class="math">\(r_Y\)</span>  </li>
<li>Test whether <span class="math">\(\text{cor}(r_X, r_Y) = 0\)</span></li>
<li>Return a p-value for each test</li>
</ol>
<p>Interpreting the results:</p>
<p>The null hypothesis <span class="math">\(H_{\phi}\)</span> is that the variables ARE conditionally independent (as the DAG claims). Therefore:</p>
<ul>
<li><strong>High p-value (&gt; 0.05)</strong>: We fail to reject <span class="math">\(H_{\phi}\)</span>. The conditional independence holds in the data. The DAG's prediction is not contradicted. The test passes!</li>
<li><strong>Low p-value (&lt; 0.05)</strong>: We reject <span class="math">\(H_{\phi}\)</span>. The conditional independence is violated. The DAG's prediction is contradicted. The test fails.</li>
</ul>
<p>Passing all tests does not <em>prove</em> the DAG is correct. Multiple different DAG structures can imply the same set of conditional independencies (these are called "Markov equivalent" DAGs). What we can do is <em>falsify</em> DAG structures that make predictions contradicted by the data. On rung 1, we can use conditional independence testing to rule out impossible causal structures, but we cannot definitively prove which structure is correct from observational data alone.</p>
<p><img alt="center" src="/figures/causality1/test-wrong-dag-1.png"></p>
<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="s">&quot;The implications: &quot;</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span> cvrt _||_ otcm | exps
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Testing fork structure against dataset 3 (wrong structure):\n\n&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Testing fork structure against dataset 3 (wrong structure):
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results3_wrong</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">localTests</span><span class="p">(</span><span class="n">dag3_wrong</span><span class="p">,</span><span class="w"> </span><span class="n">data3</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;cis&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Warning in cov2cor(cov(data)): diag(V) had non-positive or NA entries; the
## non-finite result may be dubious
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="nf">print</span><span class="p">(</span><span class="n">results3_wrong</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span>                        estimate      p.value      2.5%     97.5%
<span class="gu">##</span> cvrt _||_ otcm | exps 0.7605758 1.452368e-22 0.6732402 0.8750805
</code></pre></div>

<p>The test fails! Dataset 3 is not consistent with a fork structure. Instead, it follows a chain structure where x causes z and z causes y. Let's verify that the correct structure fits.</p>
<div class="highlight"><pre><span></span><code><span class="cp">## Testing chain structure (x -&gt; z -&gt; y) against dataset 3:</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Warning in cov2cor(cov(data)): diag(V) had non-positive or NA entries; the
## non-finite result may be dubious
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span>                          estimate p.value      2.5%     97.5%
<span class="gu">##</span> exps _||_ otcm | cvrt 0.002031441 0.98412 -0.195478 0.1993846
</code></pre></div>

<p>The chain structure fits dataset 3...</p>
<h4>Limitations of rung 1</h4>
<p>"Correlation is not causation" is only the the beginnign of the story. We can use conditional independence testing to falsify causal structures that are inconsistent with the data.</p>
<p>But we cannot prove that any particular structure is correct, we can only show that some structures are inconsistent with the data. Moreover, we cannot distinguish between correlation and causation just from observational data. The edges in our DAGs could represent predictive relationships rather than causal ones.</p>
<p>To go further, we need to climb to the second rung.</p>
<h3>Rung 2: intervention</h3>
<p>At the second rung, we move from passive observation to active manipulation. We imagine or actually perform interventions where we force a variable to take a particular value and observe what happens to other variables. This is the world of experiments, policies, and "what if I do?" questions. In pragmatic terms, we estimate the actual causal effect of changing a treatment on the outcome. </p>
<h4>What we add: causal interpretation</h4>
<p>The key addition at rung 2 is semantic: we now interpret the edges in our DAG as representing direct causal relationships, not just statistical dependencies. When we write <span class="math">\(x \rightarrow y\)</span>, we mean "x directly causes y," not just "x predicts y."</p>
<p>We add a new mathematical operator: <strong>do(X = x)</strong>, which represents forcing X to take the value x. This is different from observing X = x. When we intervene, we perform graph surgery by removing all incoming edges to X, reflecting the fact that we've overridden X's normal causes.</p>
<h4>Estimating direct and total causal effects</h4>
<p>Here we estimate causal effects by asking: "What would happen to the outcome if we <em>intervened</em> to set exposure to a  specific value?"</p>
<p>In Pearl's do-calculus notation, we write this as <span class="math">\(\mathbb{E}[Y \mid do(X = x)]\)</span> - the expected value of <span class="math">\(Y\)</span> when we set <span class="math">\(X\)</span> to <span class="math">\(x\)</span> (rather than just observe <span class="math">\(X = x\)</span>). We target <span class="math">\(\mathbb{E}[Y \mid do(X = x)]\)</span>. The total effect (ATE) is
</p>
<div class="math">$$
\tau = \mathbb{E}[Y \mid do(X = 1)] - \mathbb{E}[Y \mid do(X = 0)].
$$</div>
<p>
A direct effect can be defined as a controlled direct effect
</p>
<div class="math">$$
\mathrm{CDE}(m) = \mathbb{E}[Y \mid do(X = 1, M = m)] - \mathbb{E}[Y \mid do(X = 0, M = m)],
$$</div>
<p>
or as a natural direct effect (which requires stronger assumptions).</p>
<p>So, given a DAG, which variables should one control for to estimate <span class="math">\(\mathbb{E}[Y \mid do(X)]\)</span> from observational data? This is where the adjustment formula comes in, under certain conditions (backdoor criterion satisfied - set of variables blocks all backdoor paths from exposure to outcome and contains no descendants of exposure),</p>
<div class="math">$$\mathbb{E}[Y \mid do(X = x)] = \sum_z \mathbb{E}[Y \mid X = x, Z = z] \cdot P(Z = z)$$</div>
<p>In practice with regression, if we adjust for the right <span class="math">\(Z\)</span>, the coefficient on <span class="math">\(X\)</span> estimates the causal effect.</p>
<p>The <code>daggity</code> package has several helpful functions:</p>
<ol>
<li>The <code>paths</code> function lists all paths from exposure to outcome and tells us if they are open or not:</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="n">p4</span>
</code></pre></div>

<p><img alt="center" src="/figures/causality1/unnamed-chunk-4-1.png"></p>
<div class="highlight"><pre><span></span><code><span class="nf">paths</span><span class="p">(</span><span class="n">dag4</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;exposure&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;outcome&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## $paths</span>
<span class="c1">## [1] &quot;exposure -&gt; outcome&quot;                         </span>
<span class="c1">## [2] &quot;exposure &lt;- u1 -&gt; covariate &lt;- u2 -&gt; outcome&quot;</span>
<span class="c1">## </span>
<span class="c1">## $open</span>
<span class="c1">## [1]  TRUE FALSE</span>
</code></pre></div>

<ol>
<li>The <code>adjustmentSets</code> function tells us what to control for when estimating direct and total effets:</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="nf">adjustmentSets</span><span class="p">(</span><span class="n">dag4</span><span class="p">,</span><span class="w"> </span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;exposure&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;outcome&quot;</span><span class="p">,</span>
<span class="w">                             </span><span class="n">effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;direct&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;minimal&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>##  {}
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="nf">adjustmentSets</span><span class="p">(</span><span class="n">dag4</span><span class="p">,</span><span class="w"> </span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;exposure&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;outcome&quot;</span><span class="p">,</span>
<span class="w">                             </span><span class="n">effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;total&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;minimal&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>##  {}
</code></pre></div>

<p>which tells us that we don't need to control for anything in DAG-4 to estimate the total and direct effects. Moreover, since the only backdoor path is closed, the total and direct effects are going to be the same for this DAG. </p>
<div class="highlight"><pre><span></span><code><span class="n">data4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">causal_quartet</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">filter</span><span class="p">(</span><span class="n">dataset</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;(4) M-Bias&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">select</span><span class="p">(</span><span class="n">exposure</span><span class="p">,</span><span class="w"> </span><span class="n">outcome</span><span class="p">,</span><span class="w"> </span><span class="n">covariate</span><span class="p">,</span><span class="w"> </span><span class="n">u1</span><span class="p">,</span><span class="w"> </span><span class="n">u2</span><span class="p">)</span>
<span class="nf">lm</span><span class="p">(</span><span class="n">outcome</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">exposure</span><span class="p">,</span><span class="w"> </span><span class="n">data4</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>## 
## Call:
## lm(formula = outcome ~ exposure, data = data4)
## 
## Coefficients:
## (Intercept)     exposure  
##     -0.2175       1.0041
</code></pre></div>

<p>Lets see this for the mediator (DAG-3) (where we know the direct effect should be 0, since there is no arrow going from exposure to outcome):</p>
<div class="highlight"><pre><span></span><code><span class="n">p3</span>
</code></pre></div>

<p><img alt="center" src="/figures/causality1/unnamed-chunk-7-1.png"></p>
<div class="highlight"><pre><span></span><code><span class="nf">adjustmentSets</span><span class="p">(</span><span class="n">dag3</span><span class="p">,</span><span class="w"> </span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;exposure&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;outcome&quot;</span><span class="p">,</span>
<span class="w">                             </span><span class="n">effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;direct&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;minimal&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## { covariate }</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="nf">adjustmentSets</span><span class="p">(</span><span class="n">dag3</span><span class="p">,</span><span class="w"> </span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;exposure&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;outcome&quot;</span><span class="p">,</span>
<span class="w">                             </span><span class="n">effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;total&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;minimal&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>##  {}
</code></pre></div>

<p>So, to estimate the direct effect we need to condition on the covariate:</p>
<div class="highlight"><pre><span></span><code><span class="nf">lm</span><span class="p">(</span><span class="n">outcome</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">covariate</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">exposure</span><span class="p">,</span><span class="w"> </span><span class="n">data3</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## </span>
<span class="c1">## Call:</span>
<span class="c1">## lm(formula = outcome ~ covariate + exposure, data = data3)</span>
<span class="c1">## </span>
<span class="c1">## Coefficients:</span>
<span class="c1">## (Intercept)    covariate     exposure  </span>
<span class="c1">##    0.014874     1.067466     0.002474</span>
</code></pre></div>

<p>and we see that the direct effect of exposure on outcome is ~0. 
For the total effect, we don't need to control for anything:</p>
<div class="highlight"><pre><span></span><code><span class="nf">lm</span><span class="p">(</span><span class="n">outcome</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">exposure</span><span class="p">,</span><span class="w"> </span><span class="n">data3</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>## 
## Call:
## lm(formula = outcome ~ exposure, data = data3)
## 
## Coefficients:
## (Intercept)     exposure  
##   -0.007654     0.995610
</code></pre></div>

<h4>So much linear regression!</h4>
<p>While we have used <code>lm()</code> throughout, the DAG-based adjustment strategy (what to control for) remains valid regardless of the  statistical method. The DAG tells you what to adjust for, the statistical method determines how to adjust for it.</p>
<p>When relationships between variables arenon-linear, methods like <a href="https://noamross.github.io/gams-in-r-course/">splines</a> or <a href="https://m-clark.github.io/generalized-additive-models/">generalized additive models (GAMs)</a>  via the <a href="https://cran.r-project.org/web/packages/mgcv/index.html"><code>mgcv</code> package</a> can be used.  These allow smooth, flexible relationships while remaining interpretable - one can visualize exactly how covariates affect the outcome. For example: 
<code>gam(outcome ~ exposure + s(covariate), data = data)</code> estimates the causal effect of the exposure while relaxing the.</p>
<p>Beyond controlling directly in a regression, there are other techniques like <a href="https://academic.oup.com/ejcts/article/53/6/1112/4978231">propensity score methods</a> 
(matching or weighting by the probability of treatment) via packages like  <a href="https://kosukeimai.github.io/MatchIt/"><code>MatchIt</code></a> or <a href="https://ngreifer.github.io/WeightIt/"><code>WeightIt</code></a>. For a "best of both worlds"  approach, <a href="https://cran.r-project.org/web/packages/drtmle/vignettes/using_drtmle.html">doubly robust methods</a> combine outcome modeling with propensity scores—you get the correct answer if either model is right (see <a href="https://yqzhong7.github.io/AIPW/"><code>AIPW</code></a> package). This relies on balancing the groups (treated/untreated) on covariates by matching similar entities or reweighting the sample, so comparing outcomes is like comparing a randomized trial.</p>
<p>When treatment effects vary across individuals, <a href="https://grf-labs.github.io/grf/articles/grf.html">causal forests</a>  from the <a href="https://grf-labs.github.io/grf/"><code>grf</code> package</a> use machine learning to estimate personalized treatment effects non-parametrically. See <a href="https://arxiv.org/abs/1902.07409">Athey &amp; Wager (2019)</a> for the methodology, or the <a href="https://grf-labs.github.io/grf/articles/grf_guide.html">excellent documentation</a> that comes with the <code>grf</code> package</p>
<p>All these methods relax parametric assumptions (linearity, functional form) but cannot escape the fundamental causal  assumptions—namely, that your DAG is correct and all confounders are measured.  As Judea Pearl emphasizes: <a href="https://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf">"no causes in, no causes out"</a>—no statistical technique can create causal knowledge from purely observational data if the DAG is wrong. The fanciest machine learning model with the wrong adjustment set will give worse answers than simple linear regression with the right one.</p>
<h4>The power and limits of rung 2</h4>
<p>At rung 2, we can answer policy questions and predict the effects of interventions. We can distinguish between genuine causal effects and spurious correlations due to confounding. This is very useful for science and decision-making.</p>
<p>We can tell the average effect of intervening on x in the population: <span class="math">\(P(Y|do(X))\)</span> tells us what would happen on average if we forced X for everyone. But we cannot tell you what would have happened for a specific individual who actually experienced one value of X. We cannot answer "what if things had been different for this person?" </p>
<p>To answer that question, we need to climb to the third rung.</p>
<h3>Rung 3: counterfactuals</h3>
<p>At the third rung, we move from population-level predictions to individual-level explanations. We look at what actually happened to a specific person or instance and ask "what would have been different if...?" This is the domain of regret, responsibility, attribution, and retrospection.</p>
<h4>What we add: functional mechanisms</h4>
<p>The key addition at rung 3 is the specification of functional equations that describe how each variable is generated from its causes. We move from a DAG (which just shows which variables affect which) to a Structural Causal Model (SCM), which specifies the mechanisms.</p>
<p>For each variable, we write:
</p>
<div class="math">$$X_i = f_i(\text{Parents}(X_i), U_i)$$</div>
<p>where <span class="math">\(f_i\)</span> is a function and <span class="math">\(U_i\)</span> represents all the unmeasured factors (noise, randomness, individual variation) that affect <span class="math">\(X_i\)</span>.</p>
<p>This is a big step up in specificity. At rung 2, we only needed to know the graph structure. At rung 3, we need to know the actual functional form of how causes produce effects.</p>
<h4>What we can do: individual counterfactuals</h4>
<p>Let's work with dataset 3 (the chain structure) since it has a clear causal mechanism we can estimate. The data was actually generated from a specific structural model. Let's estimate that model and use it to answer counterfactual questions.</p>
<div class="highlight"><pre><span></span><code>## Structural equations:
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## covariate = -0.021 + 0.93*exposure + u_covariate</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## outcome = 0.015 + 1.069*covariate + u_outcome</span>
</code></pre></div>

<p>Now suppose we observe a specific individual with exposure = 1.5, covariate = 2.0, outcome = 3.5. We want to answer: "What would outcome have been for this individual if exposure had been 2.5 instead?"</p>
<p>This is a counterfactual question. To answer it, we use Pearl's three-step procedure:</p>
<ol>
<li>Abduction: Given what we observed, infer the values of the unobserved noise terms <span class="math">\(U_{covariate}\)</span> and <span class="math">\(U_{outcome}\)</span> for this specific individual</li>
<li>Action: Modify the structural equations to reflect the intervention (set exposure = 2.5)</li>
<li>Prediction: Compute what outcome would have been using the modified equations and the inferred noise terms</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="c1"># Observed values for one individual</span>
<span class="n">observed_exposure</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1.5</span>
<span class="n">observed_covariate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2.0</span>
<span class="n">observed_outcome</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">3.5</span>

<span class="c1"># Step 1: Abduction - infer the noise terms</span>
<span class="n">u_covariate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">observed_covariate</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">model_x_to_z</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">tibble</span><span class="p">(</span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">observed_exposure</span><span class="p">))</span>
<span class="n">u_outcome</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">observed_outcome</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">model_z_to_y</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">tibble</span><span class="p">(</span><span class="n">covariate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">observed_covariate</span><span class="p">))</span>

<span class="c1"># Step 2: Action - set x to counterfactual value</span>
<span class="n">counterfactual_exposure</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2.5</span>

<span class="c1"># Step 3: Prediction - compute counterfactual y</span>
<span class="c1"># First, compute what z would have been</span>
<span class="n">counterfactual_covariate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">model_x_to_z</span><span class="p">,</span><span class="w"> </span>
<span class="w">                            </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">tibble</span><span class="p">(</span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterfactual_exposure</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">u_covariate</span>

<span class="c1"># Then, compute what y would have been</span>
<span class="n">counterfactual_outcome</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">model_z_to_y</span><span class="p">,</span><span class="w"> </span>
<span class="w">                           </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">tibble</span><span class="p">(</span><span class="n">covariate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterfactual_covariate</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">u_outcome</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Step 1 - Abduction (infer noise terms):
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## u_covariate = 0.626</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span> u_outcome = 1.348
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Step 2 - Action (set x = 2.5 )
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Step 3 - Prediction:
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Counterfactual z would have been: 2.93
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Counterfactual y would have been: 4.494
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Summary:
</code></pre></div>

<div class="highlight"><pre><span></span><code>## Observed: x = 1.5 , y = 3.5
</code></pre></div>

<div class="highlight"><pre><span></span><code>##<span class="w"> </span><span class="nv">Counterfactual</span>:<span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="nv">had</span><span class="w"> </span><span class="nv">been</span><span class="w"> </span><span class="mi">2</span>.<span class="mi">5</span><span class="w"> </span>,<span class="w"> </span><span class="nv">y</span><span class="w"> </span><span class="nv">would</span><span class="w"> </span><span class="nv">have</span><span class="w"> </span><span class="nv">been</span><span class="w"> </span><span class="mi">4</span>.<span class="mi">494</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>##<span class="w"> </span><span class="nv">Effect</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">this</span><span class="w"> </span><span class="nv">individual</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">994</span>
</code></pre></div>

<h4>The Connection to Bayesian Inference</h4>
<p>What we did in step 1 (abduction) looks a lot like Bayesian inference. We observed some data and used it to infer the values of unobserved variables (the noise terms). In a Bayesian framework, we would treat the noise terms as latent variables and compute their posterior distribution given the observed data. Then, to compute counterfactuals, we would sample from this posterior and simulate what would have happened under different interventions.</p>
<p>This is exactly the approach taken in <a href="https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus">Richard McElreath's "Statistical Rethinking"</a>, where he shows how to use Bayesian inference to compute counterfactuals in structural causal models. The generative model (the SCM) becomes the inference target, and counterfactual reasoning becomes a form of posterior prediction under modified models.</p>
<h4>The Power and Limits of Rung 3</h4>
<p>At rung 3, we can answer questions about individual instances and attribute causation at the finest grain. We can reason about responsibility, regret, and explanation. We can say not just "smoking causes cancer on average" but "Bob's cancer was caused by his smoking."</p>
<p>But this power comes at a price. We need much more information than at lower rungs. Specifically, we need:</p>
<ol>
<li>The correct causal graph (rung 2 requirement)</li>
<li>The functional form of how causes produce effects</li>
<li>The distribution of unobserved factors</li>
</ol>
<p>These requirements are often difficult or impossible to satisfy with observational data alone. We typically need strong assumptions about functional forms (linearity, additivity, etc.) or additional data from experiments.</p>
<h3>Returning to the Rudder Paradox</h3>
<p>Let's generate some data that mimics the rudder situation and see how each rung of the ladder handles it.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Simulate the rudder situation</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">500</span>

<span class="c1"># Generate data</span>
<span class="c1"># W = wind (unobserved!)</span>
<span class="c1"># R = rudder position (sailor adjusts to counteract wind)</span>
<span class="c1"># D = direction (affected by both wind and rudder)</span>

<span class="n">W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># Wind is unobserved</span>
<span class="n">R</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-0.9</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w">  </span><span class="c1"># Rudder counteracts wind</span>
<span class="n">D</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">R</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w">  </span><span class="c1"># Direction depends on both</span>

<span class="n">rudder_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">tibble</span><span class="p">(</span>
<span class="w">  </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w">  </span><span class="c1"># We&#39;ll pretend we don&#39;t observe this</span>
<span class="w">  </span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">R</span><span class="p">,</span>
<span class="w">  </span><span class="n">D</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">D</span>
<span class="p">)</span>

<span class="c1"># The true causal structure</span>
<span class="n">rudder_dag</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dagitty</span><span class="p">(</span><span class="s">&#39;dag {</span>
<span class="s">  W -&gt; R</span>
<span class="s">  W -&gt; D</span>
<span class="s">  R -&gt; D</span>
<span class="s">}&#39;</span><span class="p">)</span>

<span class="n">rudder_dag</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">tidy_dagitty</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">xend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">xend</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">yend</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_dag_point</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;#C4B5A0&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_dag_text</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;#D6604D&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3.0</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">geom_dag_edges</span><span class="p">(</span><span class="n">edge_colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;#C4B5A0&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Rudder problem adjustment set &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">adjustmentSets</span><span class="p">(</span><span class="n">rudder_dag</span><span class="p">,</span><span class="w"> </span><span class="n">exposure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;R&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;D&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;total&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;minimal&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_dag</span><span class="p">()</span>
</code></pre></div>

<p><img alt="center" src="/figures/causality1/rudder-setup-1.png"></p>
<h4>Rung 1 Analysis</h4>
<p>At rung 1, we only have observational data on R and D (we can't see the wind W). Let's look at their correlation.</p>
<div class="highlight"><pre><span></span><code>## Correlation between rudder (R) and direction (D): -0.361
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="gu">##</span> `geom_smooth()` using formula = &#39;y ~ x&#39;
</code></pre></div>

<p><img alt="center" src="/figures/causality1/rudder-rung1-1.png"></p>
<p>The correlation is near zero! At rung 1, we would conclude (incorrectly) that the rudder doesn't affect the boat's direction. The problem is confounding by the unobserved wind W. The wind affects both R and D in opposite ways, misleading us when we don't account for it.</p>
<h4>Rung 2 Analysis: Intervention Reveals Truth</h4>
<p>At rung 2, we ask: what if we <em>intervene</em> to set the rudder at a specific position, overriding the sailor's control?</p>
<p>To answer this using the adjustment formula, we would need to condition on W (the wind). But W is unobserved, so we can't apply the standard backdoor adjustment. However, if we did have access to W, we could correctly estimate the causal effect.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># If we could observe W, we could adjust for it</span>
<span class="n">model_adjusted</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">D</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">R</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rudder_data</span><span class="p">)</span>
<span class="c1"># Compare to the naive (wrong) estimate</span>
<span class="n">model_naive</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">D</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">R</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rudder_data</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>##<span class="w"> </span><span class="nv">True</span><span class="w"> </span><span class="nv">causal</span><span class="w"> </span><span class="nv">effect</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">rudder</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">direction</span><span class="w"> </span><span class="ss">(</span><span class="nv">adjusting</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">wind</span><span class="ss">)</span>:
</code></pre></div>

<div class="highlight"><pre><span></span><code>##         R 
## 0.5531443
</code></pre></div>

<div class="highlight"><pre><span></span><code>##<span class="w"> </span>
##<span class="w"> </span><span class="nv">Naive</span><span class="w"> </span><span class="nv">estimate</span><span class="w"> </span><span class="ss">(</span><span class="nv">not</span><span class="w"> </span><span class="nv">adjusting</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">wind</span><span class="ss">)</span>:
</code></pre></div>

<div class="highlight"><pre><span></span><code>##           R 
## -0.05092029
</code></pre></div>

<p>When we properly adjust for the confounding wind, we see that the rudder has a substantial causal effect (around 0.5) on direction. The naive analysis severely underestimates this effect because it doesn't account for the confounding.</p>
<p>In a real experiment, we could reveal this by randomizing the rudder position. If we forced the rudder to different positions (breaking the W → R link), we would see the true causal effect.</p>
<h4>Further reading:</h4>
<ul>
<li><a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Causal Inference: What If</a> by Hernán &amp; Robins (free online textbook). </li>
<li><a href="https://www.r-causal.org/">Causal Inference in R</a> another free online textbook. </li>
<li><a href="https://mixtape.scunning.com/">Causal Inference: The Mixtape</a> by Cunningham (free, R and Stata code). </li>
<li><a href="https://github.com/malcolmbarrett/causalworkshop"><code>causalworkshop</code> R package</a> with tutorials. </li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div>
            <!-- /.entry-content -->
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://www.linkedin.com/in/pbhogale"><i class="fa fa-linkedin-square fa-lg"></i> linkedin</a></li>
    <li class="list-group-item"><a href="https://github.com/pbhogale"><i class="fa fa-github-square fa-lg"></i> github</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Recent Posts -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Recent Posts</span></h4>
  <ul class="list-group" id="recentposts">
    <li class="list-group-item"><a href="./climbing-pearls-ladder-of-causation.html">"Climbing Pearl's Ladder of Causation"</a></li>
    <li class="list-group-item"><a href="./basics-of-conformal-prediction-in-time-series-data.html">"Basics of conformal prediction in time series data"</a></li>
    <li class="list-group-item"><a href="./tidymodels-and-conformal-prediction.html">"Tidymodels and conformal prediction"</a></li>
    <li class="list-group-item"><a href="./r-torch-and-the-little-book-of-deep-learning.html">"R, Torch, and the little book of deep learning"</a></li>
    <li class="list-group-item"><a href="./becoming-a-data-scientist-an-opinionated-take-in-2020.html">"Becoming a Data Scientist : an opinionated take in 2020"</a></li>
  </ul>
</li>
<!-- End Sidebar/Recent Posts -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2025 pras
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="./theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="./theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="./theme/js/respond.min.js"></script>


    <script src="./theme/js/bodypadding.js"></script>


</body>
</html>