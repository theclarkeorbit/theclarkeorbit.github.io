<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>"R, Torch, and the little book of deep learning" - p. bhogale</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href=".//images/gravtar.jpg" rel="icon">

<link rel="canonical" href="./r-torch-and-the-little-book-of-deep-learning.html">

        <meta name="author" content="pras" />
        <meta name="description" content="These notes are meant to implement little examples from Francois Fleuret&#39;s Little Book of Deep Learning (pdf link) in r-torch. I&#39;m writing these as a fun way to dive into torch in R while surveying DL quickly. You&#39;ll need to have the book with you to understand these notes, but …" />

        <meta property="og:site_name" content="p. bhogale" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="&#34;R, Torch, and the little book of deep learning&#34;"/>
        <meta property="og:url" content="./r-torch-and-the-little-book-of-deep-learning.html"/>
        <meta property="og:description" content="These notes are meant to implement little examples from Francois Fleuret&#39;s Little Book of Deep Learning (pdf link) in r-torch. I&#39;m writing these as a fun way to dive into torch in R while surveying DL quickly. You&#39;ll need to have the book with you to understand these notes, but …"/>
        <meta property="article:published_time" content="2024-04-29" />
            <meta property="article:section" content="data_sci_tech" />
            <meta property="article:author" content="pras" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="./theme/css/bootstrap.min.css" type="text/css"/>
    <link href="./theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="./theme/css/pygments/monokai.css" rel="stylesheet">
    <link rel="stylesheet" href="./theme/css/style.css" type="text/css"/>

        <link href="./feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="p. bhogale ATOM Feed"/>

        <link href="./feeds/data_sci_tech.atom.xml" type="application/atom+xml" rel="alternate"
              title="p. bhogale data_sci_tech ATOM Feed"/>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-115756026-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', UA-115756026-1);
    </script>
    <!-- End Google Analytics Code -->
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="./" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src=".//images/gravtar.jpg" width=""/> p. bhogale            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="./pages/about.html">
                             About
                          </a></li>
                        <li >
                            <a href="./category/blog.html">Blog</a>
                        </li>
                        <li class="active">
                            <a href="./category/data_sci_tech.html">Data_sci_tech</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<style>
	#banner{
	    background-image:url(".//images/banner.jpg");
	}
</style>

<div id="banner">
	<div class="container">
		<div class="copy">
			<h1>p. bhogale</h1>
				<p class="intro">Data Sci, Quant Fin, Quant Bio.</p>
		</div>
	</div>
</div><!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="./r-torch-and-the-little-book-of-deep-learning.html"
                       rel="bookmark"
                       title="Permalink to "R, Torch, and the little book of deep learning"">
                        "R, Torch, and the little book of deep learning"
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2024-04-29T00:00:00+02:00"> Mo 29 April 2024</time>
    </span>





    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>These notes are meant to implement little examples from <a href="https://fleuret.org/francois/index.html">Francois Fleuret's</a> Little Book of Deep Learning (<a href="https://fleuret.org/public/lbdl.pdf">pdf link</a>) in r-torch. I'm writing these as a fun way to dive into torch in R while surveying DL quickly. </p>
<p>You'll need to have the book with you to understand these notes, but since it is available freely, that ought not to be an issue.</p>
<h3>Basis function regression</h3>
<p>We will generate synthetic data that is similar to the example shown in the book:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Number of samples</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span>

<span class="c1"># Randomly distributed x values from -1 to 1</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w"> </span><span class="c1"># for reproducibility</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span>
<span class="err">##</span><span class="w"> </span><span class="nx">Attaching</span><span class="w"> </span><span class="kn">package</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">stats</span><span class="err">&#39;</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">following</span><span class="w"> </span><span class="nx">objects</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="nx">masked</span><span class="w"> </span><span class="nx">from</span><span class="w"> </span><span class="err">&#39;</span><span class="kn">package</span><span class="p">:</span><span class="nx">dplyr</span><span class="err">&#39;</span><span class="p">:</span>
<span class="err">##</span><span class="w"> </span>
<span class="err">##</span><span class="w">     </span><span class="nx">filter</span><span class="p">,</span><span class="w"> </span><span class="nx">lag</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="c1"># Sorting for plotting purposes</span>

<span class="c1"># y values as the semi-circle</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>

<span class="c1"># Plotting the original semi-circle with randomly distributed x</span>
<span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Semi-Circle&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_tufte</span><span class="p">()</span>
</code></pre></div>

<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-1-1.png"></p>
<p>Following the book, we use gaussian kernels as the basis functions to fit <span class="math">\(y \sim f(x;w)\)</span>, where <span class="math">\(w\)</span> are the weights of the basis functions.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Define Gaussian basis functions</span>
<span class="n">basis_functions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">centers</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">centers</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="o">^</span><span class="m">2</span><span class="p">))</span>
<span class="p">}</span>

<span class="c1"># Centers of the Gaussian kernels, these do cover the region of space we are interested in</span>
<span class="n">centers</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span>
</code></pre></div>

<p>Now, we define our model for <span class="math">\(y\)</span>, which, for basis function regression, is a linear combination of the basis functions initialized with random weights <span class="math">\(w\)</span>. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># Initial random weights</span>
<span class="n">weightss</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_randn</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">centers</span><span class="p">),</span><span class="w"> </span><span class="n">requires_grad</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>

<span class="c1"># Calculate the model output</span>
<span class="n">model_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1"># Convert x to a torch tensor if it isn&#39;t already one</span>
<span class="w">  </span><span class="n">x_tensor</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="w">  </span><span class="c1"># Create a tensor for the basis functions evaluated at each x</span>
<span class="w">  </span><span class="c1"># Resulting tensor will have size [length(x), length(centers)]</span>
<span class="w">  </span><span class="n">basis_matrix</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_stack</span><span class="p">(</span><span class="nf">lapply</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">c</span><span class="p">)</span><span class="w"> </span><span class="nf">basis_functions</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">)),</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>

<span class="w">  </span><span class="c1"># Calculate the output using matrix multiplication</span>
<span class="w">  </span><span class="c1"># basis_matrix is [n, 10] and weights is [10, 1]</span>
<span class="w">  </span><span class="n">y_pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_matmul</span><span class="p">(</span><span class="n">basis_matrix</span><span class="p">,</span><span class="w"> </span><span class="n">weightss</span><span class="p">)</span>

<span class="w">  </span><span class="c1"># Flatten the output to match the dimension of y</span>
<span class="w">  </span><span class="nf">return</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div>

<p>Now,we will use gradient descent to minimise the MSE between the model and the real values of <span class="math">\(y\)</span> to obtain the optimal weights <span class="math">\(w^*\)</span>. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># Learning rate</span>
<span class="n">lr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.01</span>

<span class="c1"># Gradient descent loop</span>
<span class="nf">for </span><span class="p">(</span><span class="n">epoch</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">y_pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">model_y</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="w">  </span><span class="n">op</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nnf_mse_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="nf">torch_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="w">  </span><span class="c1"># Backpropagation</span>
<span class="w">  </span><span class="n">op</span><span class="o">$</span><span class="nf">backward</span><span class="p">()</span>

<span class="w">  </span><span class="c1"># Update weights</span>
<span class="w">  </span><span class="nf">with_no_grad</span><span class="p">({</span>
<span class="w">    </span><span class="n">weightss</span><span class="o">$</span><span class="nf">sub_</span><span class="p">(</span><span class="n">lr</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">weightss</span><span class="o">$</span><span class="n">grad</span><span class="p">)</span>
<span class="w">    </span><span class="n">weightss</span><span class="o">$</span><span class="n">grad</span><span class="o">$</span><span class="nf">zero_</span><span class="p">()</span>
<span class="w">  </span><span class="p">})</span>
<span class="p">}</span>
</code></pre></div>

<p>Now, we can see how good our predictions are:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Get model predictions</span>
<span class="n">fin_x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">-1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="n">length.out</span><span class="o">=</span><span class="m">100</span><span class="p">)</span>
<span class="n">final_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">model_y</span><span class="p">(</span><span class="n">fin_x</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">predicted_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fin_x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">final_y</span><span class="p">))</span>
<span class="nf">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predicted_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Original and Fitted Semi-Circle, 50 points and 10 weights, basis functions&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_tufte</span><span class="p">()</span>
</code></pre></div>

<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-5-1.png"></p>
<p><strong>Underfitting</strong> 
When the model is too small to capture the features of the data (in our case, too few weights)</p>
<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-6-1.png"></p>
<p><strong>Overfitting</strong> 
When there is too little data to properly constrain the parameters of a larger model.</p>
<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-7-1.png"></p>
<h3>Classification, and the usefulness of depth</h3>
<p>Let us generate data that looks similar to that shown in section 3.5 of the book. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># Function to generate C-shaped data</span>
<span class="n">generate_c_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">x_offset</span><span class="p">,</span><span class="w"> </span><span class="n">y_offset</span><span class="p">,</span><span class="w"> </span><span class="n">y_scale</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="p">,</span><span class="w"> </span><span class="n">xflipaxis</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">theta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kc">pi</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="o">*</span><span class="kc">pi</span><span class="o">/</span><span class="m">2</span><span class="p">)</span><span class="w">  </span><span class="c1"># Angle for C shape</span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_offset</span>
<span class="w">  </span><span class="nf">if</span><span class="p">(</span><span class="n">xflipaxis</span><span class="o">==</span><span class="bp">T</span><span class="p">){</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="o">-</span><span class="n">x</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">y_scale</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_offset</span>
<span class="w">  </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">label</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Number of points per class</span>
<span class="n">n_points</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span>

<span class="c1"># Generate data for both classes</span>
<span class="n">data_class_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">generate_c_data</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span><span class="w"> </span><span class="n">x_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                </span><span class="n">y_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">y_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span>
<span class="w">                                </span><span class="n">xflipaxis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">F</span><span class="p">)</span>
<span class="n">data_class_0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">generate_c_data</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span><span class="w"> </span><span class="n">x_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.25</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                </span><span class="n">y_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-1.0</span><span class="p">,</span><span class="w"> </span><span class="n">y_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
<span class="w">                                </span><span class="n">xflipaxis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">T</span><span class="p">)</span><span class="w">  </span><span class="c1"># Mirrored and adjusted</span>

<span class="c1"># Combine data</span>
<span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rbind</span><span class="p">(</span><span class="n">data_class_0</span><span class="p">,</span><span class="w"> </span><span class="n">data_class_1</span><span class="p">)</span>

<span class="c1"># Plotting the data</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">label</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Adjusted C-shaped Data for Classification&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;X axis&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Y axis&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_tufte</span><span class="p">()</span>
</code></pre></div>

<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-8-1.png"></p>
<p>Now, we can build a very simple neural net to classify these points and try to visualize what the trained net is doing at each layer.</p>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_module</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;ClassifierNet&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">initialize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer5</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer6</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">layer7</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">output</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_softmax</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="c1"># Initialize an environment to store activations</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">()</span>
<span class="w">  </span><span class="p">},</span>

<span class="w">  </span><span class="n">forward</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer5</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer6</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer6</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">layer7</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">activations</span><span class="o">$</span><span class="n">layer7</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">    </span><span class="n">x</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Convert the features and labels into tensors</span>
<span class="n">features</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_tensor</span><span class="p">(</span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;x&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;y&quot;</span><span class="p">)]))</span>
<span class="n">labels</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_tensor</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">label</span><span class="p">))</span>

<span class="c1"># Create a dataset using lists of features and labels</span>
<span class="n">data_classif</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">tensor_dataset</span><span class="p">(</span><span class="n">features</span><span class="p">,</span><span class="w"> </span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># Create a dataloader from the dataset</span>
<span class="n">dataloaders</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dataloader</span><span class="p">(</span><span class="n">data_classif</span><span class="p">,</span><span class="w"> </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>

<span class="c1"># defining the model</span>
<span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">net</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">  </span><span class="nf">setup</span><span class="p">(</span>
<span class="w">    </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">nn_cross_entropy_loss</span><span class="p">(),</span>
<span class="w">    </span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optim_adam</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">  </span><span class="nf">fit</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">,</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">)</span>
</code></pre></div>

<p>Now, let us see (visually) how well the model predicts some new synthetic data generated similarly. </p>
<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-10-1.png"></p>
<p>The activations for the forward model are stored in <code>model$model$activations</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">plots</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">()</span>
<span class="n">test_data</span><span class="o">$</span><span class="n">label</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test_data</span><span class="o">$</span><span class="n">label</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">()</span>
<span class="n">plots</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">label</span><span class="p">),</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Original&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;X&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Y&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_tufte</span><span class="p">()</span>

<span class="c1"># do a forward pass on the points</span>
<span class="n">Y_temp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model</span><span class="o">$</span><span class="n">model</span><span class="o">$</span><span class="nf">forward</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span><span class="w"> </span>

<span class="n">num_layers</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model</span><span class="o">$</span><span class="n">model</span><span class="o">$</span><span class="n">activations</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">length</span><span class="p">()</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">num_layers</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">df_temp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model</span><span class="o">$</span><span class="n">model</span><span class="o">$</span><span class="n">activations</span><span class="p">[[</span><span class="n">i</span><span class="p">]]</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">as.matrix</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">as_tibble</span><span class="p">()</span>
<span class="w">  </span><span class="n">df_temp</span><span class="o">$</span><span class="n">label</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test_data</span><span class="o">$</span><span class="n">label</span>
<span class="w">  </span><span class="n">plots</span><span class="p">[[</span><span class="n">i</span><span class="m">+1</span><span class="p">]]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">df_temp</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">    </span><span class="nf">geom_point</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">label</span><span class="p">),</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">    </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Layer &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">),</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;X&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Y&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">    </span><span class="nf">theme_tufte</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">patchwork</span><span class="o">::</span><span class="nf">wrap_plots</span><span class="p">(</span><span class="n">plots</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</code></pre></div>

<div class="figure">
<img src="/figures/torchlbdl/unnamed-chunk-11-1.png" alt="center" width="3" height="3" />
<p class="caption">center</p>
</div>

<p>We can see how the linear layers modify space so that the points which are initially in interlocking C shapes become spatially seperated each subsequent layer.</p>
<h3>Architectures</h3>
<h4>Multi Layer Perceptrons</h4>
<p>This is a neural net that has a series of fully connected layers seperated by activations. We will illustrate an MLP using the Penguins dataset, where we try to predict the species of a penguin from some features. Example adapted from the excellent Deep Learning with R Torch <a href="https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/">book</a>. </p>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">palmerpenguins</span><span class="p">)</span>

<span class="n">penguins</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">na.omit</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span>
<span class="n">ds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">tensor_dataset</span><span class="p">(</span>
<span class="w">  </span><span class="nf">torch_tensor</span><span class="p">(</span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">penguins</span><span class="p">[,</span><span class="w"> </span><span class="m">3</span><span class="o">:</span><span class="m">6</span><span class="p">])),</span>
<span class="w">  </span><span class="nf">torch_tensor</span><span class="p">(</span>
<span class="w">    </span><span class="nf">as.integer</span><span class="p">(</span><span class="n">penguins</span><span class="o">$</span><span class="n">species</span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span><span class="o">$</span><span class="nf">to</span><span class="p">(</span><span class="nf">torch_long</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">n_class</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">penguins</span><span class="o">$</span><span class="n">species</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">unique</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">length</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">()</span>
</code></pre></div>

<p>Now, we train a simple MLP on 75% of this dataset. </p>
<div class="highlight"><pre><span></span><code><span class="n">mlpnet</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_module</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;MLPnet&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">initialize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">din</span><span class="p">,</span><span class="w"> </span><span class="n">dhidden1</span><span class="p">,</span><span class="w"> </span><span class="n">dhidden2</span><span class="p">,</span><span class="w"> </span><span class="n">dhidden3</span><span class="p">,</span><span class="w"> </span><span class="n">n_class</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">net</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_sequential</span><span class="p">(</span>
<span class="w">      </span><span class="nf">nn_linear</span><span class="p">(</span><span class="n">din</span><span class="p">,</span><span class="w"> </span><span class="n">dhidden1</span><span class="p">),</span>
<span class="w">      </span><span class="nf">nn_relu</span><span class="p">(),</span>
<span class="w">      </span><span class="nf">nn_linear</span><span class="p">(</span><span class="n">dhidden1</span><span class="p">,</span><span class="w"> </span><span class="n">dhidden2</span><span class="p">),</span>
<span class="w">      </span><span class="nf">nn_relu</span><span class="p">(),</span>
<span class="w">      </span><span class="nf">nn_linear</span><span class="p">(</span><span class="n">dhidden2</span><span class="p">,</span><span class="w"> </span><span class="n">dhidden3</span><span class="p">),</span>
<span class="w">      </span><span class="nf">nn_relu</span><span class="p">(),</span>
<span class="w">      </span><span class="nf">nn_linear</span><span class="p">(</span><span class="n">dhidden3</span><span class="p">,</span><span class="w"> </span><span class="n">n_class</span><span class="p">)</span>
<span class="w">    </span><span class="p">)</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="n">forward</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>

<span class="n">total_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
<span class="n">train_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">floor</span><span class="p">(</span><span class="m">0.8</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">total_size</span><span class="p">)</span>
<span class="n">valid_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">total_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">train_size</span>

<span class="c1"># Generate indices and shuffle them</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">  </span><span class="c1"># For reproducibility</span>
<span class="n">indices</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="n">total_size</span><span class="p">)</span>

<span class="n">train_indices</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">indices</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">train_size</span><span class="p">]</span>
<span class="n">valid_indices</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">indices</span><span class="p">[(</span><span class="n">train_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="o">:</span><span class="n">total_size</span><span class="p">]</span>

<span class="n">train_dataset</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ds</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
<span class="n">valid_dataset</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ds</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span>

<span class="n">fitted_mlp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mlpnet</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">setup</span><span class="p">(</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">nn_cross_entropy_loss</span><span class="p">(),</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optim_adam</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">set_hparams</span><span class="p">(</span><span class="n">din</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span>
<span class="w">              </span><span class="n">dhidden1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
<span class="w">              </span><span class="n">dhidden2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
<span class="w">              </span><span class="n">dhidden3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
<span class="w">              </span><span class="n">n_class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_class</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">valid_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">valid_dataset</span><span class="p">)</span>
</code></pre></div>

<p>Now, let us visualize the validation loss during the training process.</p>
<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-14-1.png"></p>
<h4>Convolutional networks - resnets</h4>
<p>Images are usually dealt with by convolutional networks - they reduce the signal size until fully connected layers can handle it, or they output 2D signals which are themselves large. Residual networks involve an architecture where signal is taken from one layer and added to a later layer. </p>
<p>We will build a very simple resnet for the task of image classification, example loosely based on the DL+SC with R torch <a href="https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/image_classification_1.html">book</a>.</p>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">torchvision</span><span class="p">)</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>
<span class="nf">torch_manual_seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>

<span class="n">dir</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&quot;~/.torch-datasets&quot;</span>

<span class="n">train_ds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">torchvision</span><span class="o">::</span><span class="nf">kmnist_dataset</span><span class="p">(</span><span class="n">train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span>
<span class="w">  </span><span class="n">dir</span><span class="p">,</span>
<span class="w">  </span><span class="n">download</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span>
<span class="w">  </span><span class="n">transform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">      </span><span class="nf">transform_to_tensor</span><span class="p">()</span><span class="w"> </span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>

<span class="n">valid_ds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">torchvision</span><span class="o">::</span><span class="nf">mnist_dataset</span><span class="p">(</span><span class="n">train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span>
<span class="w">  </span><span class="n">dir</span><span class="p">,</span>
<span class="w">  </span><span class="n">transform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">      </span><span class="nf">transform_to_tensor</span><span class="p">()</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>

<span class="n">train_dl</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dataloader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span>
<span class="w">  </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">128</span><span class="p">,</span>
<span class="w">  </span><span class="n">shuffle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span>
<span class="p">)</span>
<span class="n">valid_dl</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dataloader</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span><span class="w"> </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">128</span><span class="p">)</span>
</code></pre></div>

<p>There, we have downloaded the Kanji MNIST dataset to use to test our simple resnet. The model below is partially based on <a href="https://jtr13.github.io/cc21fall2/tutorial-on-r-torch-package.html">this tutorial</a> from 2021.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Define a simple Residual Block</span>
<span class="n">simple_resblock</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_module</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;SimpleResBlock&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">initialize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">conv1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span><span class="w"> </span><span class="n">channels</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">relu1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_relu</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">conv2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span><span class="w"> </span><span class="n">channels</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">relu2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_relu</span><span class="p">()</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="n">forward</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">identity</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">out</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">relu1</span><span class="p">(</span><span class="n">self</span><span class="o">$</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="w">    </span><span class="n">out</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="nf">relu2</span><span class="p">(</span><span class="n">self</span><span class="o">$</span><span class="nf">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
<span class="w">    </span><span class="n">out</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">identity</span><span class="w"> </span><span class="c1">#the eponymous residual operation.</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>


<span class="n">net</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_module</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;Net&quot;</span><span class="p">,</span>

<span class="w">  </span><span class="n">initialize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">conv1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv2d</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">32</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">conv2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv2d</span><span class="p">(</span><span class="m">32</span><span class="p">,</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">dropout1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_dropout</span><span class="p">(</span><span class="m">0.25</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">dropout2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_dropout</span><span class="p">(</span><span class="m">0.5</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">fc1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">9216</span><span class="p">,</span><span class="w"> </span><span class="m">128</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">resblock1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">simple_resblock</span><span class="p">(</span><span class="m">32</span><span class="p">)</span><span class="w"> </span><span class="c1"># 32 since its used after first conv layer that o/ps 32 channels</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">resblock2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">simple_resblock</span><span class="p">(</span><span class="m">64</span><span class="p">)</span><span class="w"> </span><span class="c1"># used after the second conv layer that outputs 64 channels</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">fc2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_linear</span><span class="p">(</span><span class="m">128</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">)</span>
<span class="w">  </span><span class="p">},</span>

<span class="w">  </span><span class="n">forward</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                                  </span><span class="c1"># N * 1 * 28 * 28</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">conv1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                     </span><span class="c1"># N * 32 * 26 * 26</span>
<span class="w">      </span><span class="nf">nnf_relu</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">     </span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">resblock1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                 </span><span class="c1"># the residual block</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">conv2</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                     </span><span class="c1"># N * 64 * 24 * 24</span>
<span class="w">      </span><span class="nf">nnf_relu</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">resblock2</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                 </span><span class="c1"># second residual block</span>
<span class="w">      </span><span class="nf">nnf_max_pool2d</span><span class="p">(</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                </span><span class="c1"># N * 64 * 12 * 12</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">dropout1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">      </span><span class="nf">torch_flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">     </span><span class="c1"># N * 9216</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">fc1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">                       </span><span class="c1"># N * 128</span>
<span class="w">      </span><span class="nf">nnf_relu</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">dropout2</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">fc2</span><span class="p">()</span><span class="w">                           </span><span class="c1"># N * 10</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>
</code></pre></div>

<p>Now, we will train this on our data. </p>
<div class="highlight"><pre><span></span><code><span class="n">fitted</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">net</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">  </span><span class="nf">setup</span><span class="p">(</span>
<span class="w">    </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">nn_cross_entropy_loss</span><span class="p">(),</span>
<span class="w">    </span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optim_adam</span><span class="p">,</span>
<span class="w">    </span><span class="n">metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span>
<span class="w">      </span><span class="nf">luz_metric_accuracy</span><span class="p">()</span>
<span class="w">    </span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">  </span><span class="nf">fit</span><span class="p">(</span><span class="n">train_dl</span><span class="p">,</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</code></pre></div>

<p>Let's see how it does on the test set. </p>
<div class="highlight"><pre><span></span><code><span class="n">model_eval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span><span class="w"> </span><span class="n">valid_dl</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model_eval</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1">## A `luz_module_evaluation`</span>
<span class="c1">## ── Results ─────────────────────────────────────────────────────────────────────</span>
<span class="c1">## loss: 0.3452</span>
<span class="c1">## acc: 0.899</span>
</code></pre></div>

<h4>Attention and transformers</h4>
<p>It seems to be a rule that any text on the internet mentioning these words must have this graphic from the original "Attention is all you need" <a href="https://arxiv.org/abs/1706.03762">paper</a>. 
<img alt="" src="attention.png">.
Instead of the paper, read <a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention">this</a> excellent article by <a href="https://sebastianraschka.com/">Sebastian Raschka</a>. Transformers and Attention deserve a seperate article, but for now, it is worth mentioning that the inbuilt modules <code>torch::nn_embedding</code> and <code>torch::nn_multihead_attention</code> can be used to build out a simple transformer. Further topics mentioned in LBDL, the post above:
1. Causal self attention (nothing to do with causality in the Judea Pearl sense, just a condition on not letting tokens later in the sequence influence tokens that came before them).
2. Generative Pre-trained Transformer (GPT)
3. Vision transformer</p>
<h3>Applications</h3>
<p>Some simple example code based on the topics mentioned in the little book of deep learning.</p>
<h4>Image denoising</h4>
<p>First, we want to generate some noisy images, we use some sample images. First, we would like to load and see these images in memory.</p>
<div class="highlight"><pre><span></span><code><span class="n">image_dir</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&quot;./sample_photos/&quot;</span>
<span class="n">image_files</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list.files</span><span class="p">(</span><span class="n">image_dir</span><span class="p">,</span><span class="w"> </span><span class="n">pattern</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;\\.jpg$&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">full.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>
<span class="n">images</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lapply</span><span class="p">(</span><span class="n">image_files</span><span class="p">,</span><span class="w"> </span><span class="n">image_read</span><span class="p">)</span>

<span class="c1"># Determine maximum dimensions</span>
<span class="n">max_width</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="nf">sapply</span><span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="nf">image_info</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">$</span><span class="n">width</span><span class="p">))</span>
<span class="n">max_height</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="nf">sapply</span><span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="nf">image_info</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">$</span><span class="n">height</span><span class="p">))</span>

<span class="c1"># Pad and resize images</span>
<span class="n">padded_images</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lapply</span><span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nf">image_background</span><span class="p">(</span><span class="nf">image_resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="n">max_width</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;x&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">max_height</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;!&#39;</span><span class="p">)),</span><span class="w"> </span><span class="s">&quot;white&quot;</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Function to properly convert ImageMagick image data to a torch tensor</span>
<span class="n">padded_tensors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lapply</span><span class="p">(</span><span class="n">padded_images</span><span class="p">,</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1"># Extract pixel data as array</span>
<span class="w">  </span><span class="n">array</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.integer</span><span class="p">(</span><span class="nf">image_data</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>

<span class="w">  </span><span class="c1"># Convert the array to a tensor and normalize it</span>
<span class="w">  </span><span class="n">tensor</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="nf">torch_tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">torch_float32</span><span class="p">())</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">255</span>

<span class="w">  </span><span class="c1"># Permute dimensions to have channel as the first dimension (if needed)</span>
<span class="w">  </span><span class="n">tensor</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tensor</span><span class="o">$</span><span class="nf">permute</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">))</span>

<span class="w">  </span><span class="nf">return</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="p">})</span>


<span class="c1"># Function to add random noise to an image tensor</span>
<span class="n">add_noise_to_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">noise_level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1"># Generate noise</span>
<span class="w">  </span><span class="n">noise</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">torch_rand_like</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">noise_level</span>
<span class="w">  </span><span class="c1"># Add noise to the image</span>
<span class="w">  </span><span class="n">noisy_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">image_tensor</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">noise</span>
<span class="w">  </span><span class="c1"># Ensure the noisy image is still within the valid range [0, 1] if normalized or [0, 255] if not</span>
<span class="w">  </span><span class="c1"># Assuming the image tensor is normalized between 0 and 1</span>
<span class="w">  </span><span class="c1"># noisy_image &lt;- torch_clamp(noisy_image, min = 0, max = 1)</span>
<span class="w">  </span><span class="nf">return</span><span class="p">(</span><span class="n">noisy_image</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Function to display a torch tensor as an image using magick</span>
<span class="n">plot_tensor_as_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">tensor</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">as.array</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">aperm</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="n">magick</span><span class="o">::</span><span class="nf">image_read</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">imgg</span>
<span class="w">  </span><span class="n">imgg</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nf">plot</span><span class="p">()</span>
<span class="w">  </span><span class="c1"># return(imgg)</span>
<span class="p">}</span>

<span class="c1"># Plot the first tensor</span>
<span class="nf">plot_tensor_as_image</span><span class="p">(</span><span class="n">padded_tensors</span><span class="p">[[</span><span class="m">1</span><span class="p">]])</span>
</code></pre></div>

<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-20-1.png"></p>
<div class="highlight"><pre><span></span><code><span class="n">padded_tensors</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">add_noise_to_image</span><span class="p">(</span><span class="n">noise_level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">nimgg</span>
<span class="nf">plot_tensor_as_image</span><span class="p">(</span><span class="n">nimgg</span><span class="p">)</span>
</code></pre></div>

<p><img alt="center" src="/figures/torchlbdl/unnamed-chunk-20-2.png"></p>
<div class="highlight"><pre><span></span><code><span class="n">noisy_padded_tensors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sapply</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">padded_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">FUN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">add_noise_to_image</span><span class="p">,</span><span class="w"> </span><span class="n">noise_level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span>

<span class="c1"># Now we will construct a dataset where the noisy images are inputs and the clean images are outputs.</span>

<span class="c1"># # Define the dataset</span>
<span class="n">paired_dataset</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dataset</span><span class="p">(</span>
<span class="w">  </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;PairedTensorDataset&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">initialize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">inputs</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">targets</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="n">.getitem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nf">list</span><span class="p">(</span><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="n">x</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="o">$</span><span class="n">y</span><span class="p">[[</span><span class="n">i</span><span class="p">]])</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="n">.length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nf">length</span><span class="p">(</span><span class="n">self</span><span class="o">$</span><span class="n">x</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Create an instance of the dataset</span>
<span class="n">img_dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">paired_dataset</span><span class="p">(</span><span class="n">noisy_padded_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">padded_tensors</span><span class="p">)</span>

<span class="c1"># Create a DataLoader</span>
<span class="n">img_datlod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dataloader</span><span class="p">(</span><span class="n">img_dat</span><span class="p">,</span><span class="w"> </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>
</code></pre></div>

<p>Now, we will train a very simple de-noising auto-encoder and test it on a new image. It will consist of a set of encoder layers that generate a compressed representation of the images and then decoder layers that will regenrate the originals back based on the copmopressed representation. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># Define the autoencoder model</span>
<span class="n">autoencoder</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_module</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;DenoisingAutoencoder&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">initialize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Encoder layers</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">enc_conv1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">out_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                </span><span class="n">kernel_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w"> </span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">enc_relu1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_relu</span><span class="p">()</span><span class="w"> </span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">enc_conv2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">,</span><span class="w"> </span><span class="n">out_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">32</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                </span><span class="n">kernel_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">enc_relu2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_relu</span><span class="p">()</span><span class="w"> </span>

<span class="w">    </span><span class="c1"># Decoder layers</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">dec_conv1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv_transpose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">32</span><span class="p">,</span><span class="w"> </span><span class="n">out_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                          </span><span class="n">kernel_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">output_padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">dec_relu1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_relu</span><span class="p">()</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">dec_conv2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_conv_transpose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">,</span><span class="w"> </span><span class="n">out_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                          </span><span class="n">kernel_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">output_padding</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span>
<span class="w">    </span><span class="n">self</span><span class="o">$</span><span class="n">dec_sigmoid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nn_sigmoid</span><span class="p">()</span><span class="w">  </span>
<span class="w">  </span><span class="p">},</span>

<span class="w">  </span><span class="n">forward</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Encoder</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1"># 3  939 1560</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">enc_conv1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1"># 16 469 779</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">enc_relu1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1">#16 469 779</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">enc_conv2</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1"># 32 234 389 </span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">enc_relu2</span><span class="p">()</span><span class="w"> </span><span class="c1"># 32 234 389</span>
<span class="w">    </span><span class="c1"># Decoder</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">dec_conv1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1"># 16 469 779</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">dec_relu1</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1"># 16 470 780</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">dec_conv2</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="c1"># 3  939 1559</span>
<span class="w">      </span><span class="n">self</span><span class="o">$</span><span class="nf">dec_sigmoid</span><span class="p">()</span><span class="w"> </span><span class="c1"># 3  939 1559</span>
<span class="w">    </span><span class="n">x</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Setup the model with luz</span>
<span class="n">model_a</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">autoencoder</span><span class="p">()</span><span class="w"> </span>
<span class="n">model_setup</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">autoencoder</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span>
<span class="w">  </span><span class="nf">setup</span><span class="p">(</span>
<span class="w">    </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">nn_mse_loss</span><span class="p">(),</span>
<span class="w">    </span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optim_adam</span><span class="p">,</span>
<span class="w">    </span><span class="n">metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span>
<span class="w">      </span><span class="nf">luz_metric_mse</span><span class="p">()</span>
<span class="w">    </span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span>

<span class="c1"># model_a$forward(noisy_padded_tensors[[1]]) |&gt; dim()</span>

<span class="n">fitted_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model_setup</span><span class="w"> </span><span class="o">|&gt;</span>
<span class="w">  </span><span class="nf">fit</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">img_datlod</span><span class="p">,</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span>
</code></pre></div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div>
            <!-- /.entry-content -->
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://www.linkedin.com/in/pbhogale"><i class="fa fa-linkedin-square fa-lg"></i> linkedin</a></li>
    <li class="list-group-item"><a href="https://github.com/pbhogale"><i class="fa fa-github-square fa-lg"></i> github</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Recent Posts -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Recent Posts</span></h4>
  <ul class="list-group" id="recentposts">
    <li class="list-group-item"><a href="./r-torch-and-the-little-book-of-deep-learning.html">"R, Torch, and the little book of deep learning"</a></li>
    <li class="list-group-item"><a href="./becoming-a-data-scientist-an-opinionated-take-in-2020.html">"Becoming a Data Scientist : an opinionated take in 2020"</a></li>
    <li class="list-group-item"><a href="./linear-and-mixed-integer-programming.html">"Linear and mixed integer programming"</a></li>
    <li class="list-group-item"><a href="./the-invisible-hand.html">"The Invisible Hand"</a></li>
    <li class="list-group-item"><a href="./greta-playground.html">"greta playground"</a></li>
  </ul>
</li>
<!-- End Sidebar/Recent Posts -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2024 pras
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="./theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="./theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="./theme/js/respond.min.js"></script>


    <script src="./theme/js/bodypadding.js"></script>


</body>
</html>